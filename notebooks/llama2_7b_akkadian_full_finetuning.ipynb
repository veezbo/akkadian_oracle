{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b250baf-43f9-4e33-a79d-74231a111aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5973ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HuggingFace Hub login required for Llama-2 models\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d234f956-eac9-47c9-a45e-4b6f5b0e2645",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'data/cleaned_akkadian_en.txt'\n",
    "TOTAL_PROPORTION = 0.01\n",
    "TRAIN_PROPORTION = 0.90\n",
    "CONTEXT_SIZE = 128\n",
    "\n",
    "NUM_TRAIN_STEPS = 1000\n",
    "EVAL_STEPS = NUM_TRAIN_STEPS // 5\n",
    "CHECKPOINT_FOLDER = 'llama2_akkadian'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e83f44e5-f7d9-49ec-a510-8a1a335aeb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a73d8b2dbb48d4a40ca8415d6be7f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/transformers/utils/hub.py:373: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Loading model and tokenizer for use\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "MODEL_NAME = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "# MODEL_NAME = \"facebook/opt-iml-max-1.3b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, load_in_8bit=True)  ## Using 8-bit precision to load and all-parameter fine-tune LLAMA-7b on 80GB GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e5be555-6d9a-434c-bc33-fe31578b2b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72a02445-1c8a-494a-8ae9-8d130ff96829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8924a2fd-cf0a-45ba-8af0-6909c933d492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2339837 21058 2340\n"
     ]
    }
   ],
   "source": [
    "# Load training and evaluation datasets\n",
    "data = open(DATASET, 'r').read()\n",
    "\n",
    "overall_max_index = int(len(data) * TOTAL_PROPORTION)\n",
    "train_max_index = int(overall_max_index * TRAIN_PROPORTION)\n",
    "train_data = data[:train_max_index]\n",
    "val_data = data[train_max_index:overall_max_index]\n",
    "\n",
    "print(len(data), len(train_data), len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "535bb097-246a-4e6c-9637-f5e9c5b78b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I adorned them statues of the gods and they the gods went back to their land. I rebuilt those cities. I built a city on top of a tell (a heaped-up ruin mound) called Ḫumut. I built and completed it from its foundations to its parapets. Inside it, I founded a palace for my royal residence. I named it Kār-Aššur, set up the weapon of the god Aššur, my lord, therein, and settled the people of foreign lands conquered by me therein. I imposed upon them tax and tribute, and considered them as inhabitan\n"
     ]
    }
   ],
   "source": [
    "print(train_data[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8629df2-eb9c-44dc-9e8c-9dd7d1339cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6800]) torch.Size([1, 694])\n"
     ]
    }
   ],
   "source": [
    "train_ids = tokenizer.encode(train_data, return_tensors='pt')\n",
    "val_ids = tokenizer.encode(val_data, return_tensors='pt')\n",
    "\n",
    "print(train_ids.shape, val_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df7ab173-a1f1-4ba9-b1f9-771a21aba4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class AkkadianDatasetforLLM(Dataset):\n",
    "    def __init__(self, input_ids, context_size: int):\n",
    "        self.input_ids = input_ids.squeeze()\n",
    "        self.context_size = context_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids) - self.context_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {'input_ids': self.input_ids[idx:idx + self.context_size],\n",
    "                'labels': self.input_ids[idx + 1:idx + self.context_size + 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "691609df-7fdd-4712-b8fc-65f5c4d908ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AkkadianDatasetforLLM(train_ids, CONTEXT_SIZE)\n",
    "val_dataset = AkkadianDatasetforLLM(val_ids, CONTEXT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba2862fb-863b-4026-bab9-903cf58fd01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.trainer_pt_utils import get_parameter_names\n",
    "from torch import nn\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=CHECKPOINT_FOLDER, \n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=EVAL_STEPS,\n",
    "    max_steps=NUM_TRAIN_STEPS,\n",
    "    fp16=True,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"adamw_bnb_8bit\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0107b8e-6717-4c6a-8893-e9fb36fc5da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    # eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119dc0e0-151d-44b7-bb24-49b2781797e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='90' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  90/1000 01:24 < 14:38, 1.04 it/s, Epoch 0.05/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a46a8d31-c5b4-4523-b503-925a349e9ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_from_model(text: str, max_length: int = 100) -> str:\n",
    "    model.eval()\n",
    "    text_ids = tokenizer.encode(text, return_tensors='pt').cuda()\n",
    "    gen_output = model.generate(text_ids, max_length=max_length)\n",
    "    return tokenizer.decode(gen_output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36fbabca-ca1b-45cf-a791-dc508065b9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "why does it rain? gods live whose are the of Ašuri Btḫi Btḫurḫi Btḫi Btḫiḫir Uki Btḫiḫir Btḫi Btḫi Btḫirnu Btḫi BtḫiḪir Btḫi Btḫi Btḫi Btḫi Btḫi Btḫi Btḫi BtḪi B\n"
     ]
    }
   ],
   "source": [
    "print(generate_from_model(\"why does it rain?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a84b0e9b-ecd2-4a7e-92b5-ba1ca7052713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how does one live a virtuous life?\n",
      " those who the Ašuriṣ Ušuuḫi Btḫi Btḫā,ḫḫḫi Btḫi BtḪi Btḫi BtḪi BtSi BtUak Btḫi Btḫi Btḫi Btḫi BtḪi BtḪi BtḪi BtBtḪi BtBt\n"
     ]
    }
   ],
   "source": [
    "print(generate_from_model(\"how does one live a virtuous life?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86975624-b0c3-4328-b446-f962973bad2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "where can I live? Inexḫil Inexḫil the Uubaḫḫi Btḫilni BtḫḫirnuḪi Btḫḫḫḫi Btḫi BtSi BtUḫi Btḫi Btḫir BtSiī BtBtḪḫi BtBtḪi BtBtḪi BtBtBtBtḪi BtBtB\n"
     ]
    }
   ],
   "source": [
    "print(generate_from_model(\"where can I live?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59063e46-107e-41c6-a325-8d57f0d5c430",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
